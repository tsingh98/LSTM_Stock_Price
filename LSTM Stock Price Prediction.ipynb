{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This project aims to utilize Long Short Term Memory neural networks on a variable set of momentum indicators to predict stock price evolution.\n",
    "\n",
    "## The dataset we use daily stock price data for 10 tickers, taken from the quandl python api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import quandl\n",
    "quandl.ApiConfig.api_key = \"47d6qS5DtPwi1miuHQHh\"\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Momentum Indicators\n",
    "Firstly it is necesarry to establish our predictive variables. We calculate the following momentum indicators:\n",
    "\n",
    "- MACD:\n",
    "    - Moving Average Convergence Divergence expresses the relationship between 2 moving averages of a security. We compute it by subtracting the 26 day exponential moving average (EMA) from the 12 day EMA. \n",
    "- Stochastic RSI:\n",
    "    - The Relative Strength Index (RSI) describes a momentum indicator that measures the magnitude of recent price changes in order to evaluate overbought or oversold conditions in the price of a stock or other asset\n",
    "    - The Stochastic RSI applies the stochastic oscillator formula to the relative strength index.\n",
    "    - It indicates overbought and oversold conditions in a security's price\n",
    "- Bollinger Percentage\n",
    "    -Quantifies the relationship between Bollinger bands and price action to indicate overbought/oversold conditions\n",
    "- Bollinger Band Width- Difference between upper and lower Bollinger bands\n",
    "- Ease of Movement- Volume and momentum oscialltor which expresses the ease at which price moves determined by the volume profile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Indicators(df,period):\n",
    "    #df['pct_change'] = df.open.pct_change()\n",
    "    #df['log_return'] = np.log(1 + df['pct_change'])\n",
    "    \n",
    "    df['Middle Band'] = df['open'].rolling(window=20).mean()\n",
    "    df['20 Day STD'] = df['open'].rolling(window=20).std()\n",
    "    df['Upper Band']= df['Middle Band']+df['20 Day STD']*2\n",
    "    df['Lower Band']= df['Middle Band']-df['20 Day STD']*2\n",
    "    df['Band Width']= ((df['Upper Band'] - df['Lower Band']) / df['Middle Band']) * 100\n",
    "    df['Bollinger_percent'] = ((df.close-df['Lower Band'])/(df['Upper Band']-df['Lower Band']))*100\n",
    "    \n",
    "    \n",
    "    #df['exp1'] = df.apply(lambda x: x['close'].ewm(span=12,min_periods=12).mean())\n",
    "    #df['exp2'] = df.apply(lambda x: x['close'].ewm(span=26,min_periods=26).mean())\n",
    "    df['exp1'] = df.close.ewm(span=12,min_periods=12, adjust=False).mean()\n",
    "    df['exp2'] = df.close.ewm(span=26,min_periods=26, adjust=False).mean()\n",
    "    \n",
    "    df['MACD'] = df['exp1']-df['exp2']\n",
    "    \n",
    "    df['exp3'] = df['MACD'].ewm(span=9, adjust=False).mean()\n",
    "    \n",
    "    RSI_computer = pd.DataFrame(df.close.shift().diff())\n",
    "    RSI_computer.rename(columns={'close': 'delta'},inplace = True)\n",
    "    \n",
    "    RSI_computer['u'] = RSI_computer.delta * 0\n",
    "    RSI_computer['d'] = RSI_computer.u.copy()\n",
    "    \n",
    "    RSI_computer['u'].loc[(RSI_computer.delta > 0)] = RSI_computer.delta.loc[(RSI_computer.delta >0)]\n",
    "    RSI_computer['d'].loc[(RSI_computer.delta < 0)] = -RSI_computer.delta.loc[(RSI_computer.delta <0)]\n",
    "    \n",
    "    RSI_computer['u'].loc[RSI_computer.u.index[period-1]]= np.mean(RSI_computer.u.loc[:period])\n",
    "    RSI_computer.u = RSI_computer.u.drop(RSI_computer.u.index[:(period-1)])\n",
    "    \n",
    "    RSI_computer['d'].loc[RSI_computer.d.index[period-1]]= np.mean(RSI_computer.d.loc[:period])\n",
    "    RSI_computer.d = RSI_computer.d.drop(RSI_computer.d.index[:(period-1)])\n",
    "    \n",
    "    RSI_computer['RS'] = RSI_computer.u.ewm(span=period-1, adjust=False).mean()/ RSI_computer.d.ewm(span=period-1, adjust=False).mean()\n",
    "    \n",
    "    df['RSI_final']= pd.Series(100-100/(1+RSI_computer.RS))\n",
    "    #df.join(RSI_final) \n",
    "    #print('Fine')\n",
    "    \n",
    "    df['Stochastic_Oscillator'] = (df.close-df.low.rolling(14).min()/df.high.rolling(14).max()-df.low.rolling(14).min())*100 \n",
    "    #print('Fine2')\n",
    "    \n",
    "    dm = ((df['high'].shift() + df['low']/2) - ((df['high'].shift() + df['low'].shift())/2))\n",
    "    br = (df['volume'] / 100000000) / ((df['high'] - df['low']))\n",
    "    \n",
    "    EVM = dm / br \n",
    "    df['EVM_MA'] = pd.Series(EVM.rolling(14).mean()) \n",
    "    \n",
    "    \n",
    "    df_prelim = df[['date','Bollinger_percent','MACD','exp3','RSI_final','Stochastic_Oscillator','close','EVM_MA','Band Width']]\n",
    "    \n",
    "    \n",
    "    \n",
    "    df_final = DealWithMissing(df_prelim)\n",
    "    #print('Fine3')\n",
    "    #df_final2 = Normalise(df_final)\n",
    "    #print('Fine4')\n",
    "    df_final['Difference']= df_final['close'].diff(periods=-1)\n",
    "    #print('Fine5')\n",
    "    df_final['UP_DOWN'] = np.where(df_final['Difference']>0,1,0) \n",
    "    #print('Fine6')\n",
    "    df_final3 = DealWithMissing(df_final)\n",
    "\n",
    "        \n",
    "    \n",
    "    df_submit = df_final3[['date','Bollinger_percent','MACD','exp3','RSI_final','Stochastic_Oscillator','close','EVM_MA','Band Width','UP_DOWN']]\n",
    "    \n",
    "            \n",
    "    \n",
    "    return(df_submit,df_final3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is often useful to standardize our variables by subtracting the variable means and dividing by the standard deviation for faster training in lieu of gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Normalise(df):\n",
    "    \n",
    "    normalise_df = (df-df.mean())/df.std()\n",
    "    \n",
    "    return(normalise_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We clean the dataset by removing missing data as there is risk of adding bias with backfilling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DealWithMissing(df):\n",
    "    fixed_df = df.dropna(how='any')\n",
    "    return(fixed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "We create functions to generate dicts for each ticker and  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_maker(df,list_tickers):\n",
    "    dict1 = {}\n",
    "    for i in list_tickers:\n",
    "        dict1[i]=df[df['ticker']==i]\n",
    "    return(dict1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We reshape our feature set into 60 day intervals, creating a 3D matrix for our training set. Additionally we separate our target of close prices.\n",
    "\n",
    "We construct the Long short term memory model with 4 hidden layers with 20% dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_Price(df,key):\n",
    "    \n",
    "    #df = Indicative_dicts['AAPL']\n",
    "    \n",
    "    colnum=df.shape[0]\n",
    "    colnum-1000\n",
    "\n",
    "    \n",
    "    sc = MinMaxScaler(feature_range = (0, 1))\n",
    "    sc1 = MinMaxScaler(feature_range = (0, 1))\n",
    "    \n",
    "    #sc1 = MinMaxScaler(feature_range = (0, 1))\n",
    "\n",
    "    #Real stock values for testing\n",
    "    Close_prices = df[['date','close']]\n",
    "    Close_prices= Close_prices.iloc[colnum-1000:,:]\n",
    "    #Close_prices = Close_prices.reshape(-1,1)\n",
    "    #Close_prices = sc1.fit_transform(Values_price)\n",
    "    \n",
    "    #f1=Close_prices[['close']]\n",
    "    #f1.reshape(-1,1)\n",
    "    \n",
    "    #scaled features\n",
    "    Features = df.iloc[:,1:9].values\n",
    "    \n",
    "    f1 = Features[:,5]\n",
    "    f1=f1.reshape(-1,1)\n",
    "    #Placeheld = sc1.fit_transform(f1)\n",
    "    Features_Scaled = sc.fit_transform(Features)\n",
    "    #Values_c = ADI_df.iloc[:,9].values\n",
    "    \n",
    "        \n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    \n",
    "    for i in range(60,colnum-1000):\n",
    "        X_train.append(Features_Scaled[i-60:i,:])\n",
    "        y_train.append(Features_Scaled[i,5])\n",
    "        \n",
    "    X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "    \n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    \n",
    "    for i in range(colnum-1000,colnum):\n",
    "        X_test.append(Features_Scaled[i-60:i,:])\n",
    "        y_test.append(Features_Scaled[i,5])\n",
    "        \n",
    "    X_test, y_test = np.array(X_test), np.array(y_test)    \n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 8))\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    regressor = Sequential()    \n",
    "    # Adding the first LSTM layer and some Dropout regularisation\n",
    "    regressor.add(LSTM(units = 50, return_sequences = True, input_shape = (X_train.shape[1], 8)))\n",
    "    regressor.add(Dropout(0.2))\n",
    "    \n",
    "    # Adding a second LSTM layer and some Dropout regularisation\n",
    "    regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "    regressor.add(Dropout(0.2))\n",
    "    \n",
    "    # Adding a third LSTM layer and some Dropout regularisation\n",
    "    regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "    regressor.add(Dropout(0.2))\n",
    "    \n",
    "    # Adding a fourth LSTM layer and some Dropout regularisation\n",
    "    regressor.add(LSTM(units = 50))\n",
    "    regressor.add(Dropout(0.2))\n",
    "    \n",
    "    # Adding the output layer\n",
    "    regressor.add(Dense(units = 1))\n",
    "    \n",
    "    # Compiling the RNN\n",
    "    regressor.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "    \n",
    "    # Fitting the RNN to the Training set\n",
    "    regressor.fit(X_train, y_train, epochs = 15, batch_size = 32,validation_split=0.2,verbose=0)\n",
    "\n",
    "\n",
    "        \n",
    "    predicted_stock_price = regressor.predict(X_test)\n",
    "    predicted_stock_price = sc1.inverse_transform(predicted_stock_price)\n",
    "    predicted_stock_price = pd.DataFrame(predicted_stock_price)\n",
    "    \n",
    "   # together = pd.concat([Close_prices, pd.DataFrame(predicted_stock_price)], axis=1, ignore_index=True)\n",
    "    together = pd.concat([Close_prices.reset_index(drop=True), predicted_stock_price], axis=1)    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we load the data for 10 tickers and train our models for each ticker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers_10_data=pd.read_csv('./tickers.csv')\n",
    "list_tickers=tickers_10_data['Ticker'].tolist()\n",
    "\n",
    "\n",
    "_10_tickers_data = pd.read_csv(\"./Data_main.csv\") \n",
    "\n",
    "\n",
    "_10_tickers_data = _10_tickers_data.iloc[::-1]\n",
    "\n",
    "if(_10_tickers_data.isnull().values.any()):\n",
    "    Tickers_ready = DealWithMissing(_10_tickers_data)\n",
    "else:\n",
    "    Tickers_ready=_10_tickers_data \n",
    "\n",
    "Ticks_dict = dict_maker(Tickers_ready,list_tickers)\n",
    "\n",
    "Indicative_dicts = {}\n",
    "Feature_eng_dicts = {}\n",
    "\n",
    "for key in Ticks_dict:\n",
    "    Indicative_dicts[key],Feature_eng_dicts[key]=Indicators(Ticks_dict[key],14)\n",
    "\n",
    "for key in Indicative_dicts:\n",
    "    LSTM_Price(Indicative_dicts[key],key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us observe the out of sample performance for our 10 tickers. Note we test on the dates consequently following our training dates to utilize the sequential retention of the neural LSTMs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Plots/AAPL-1.png\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Plots/ADI-1.png\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Plots/CNP-1.png\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Plots/DLTR-1.png\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Plots/FLS-1.png\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Plots/HAS-1.png\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Plots/PBCT-1.png\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Plots/RHI-1.png\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Plots/TGT-1.png\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Plots/WBA-1.png\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
